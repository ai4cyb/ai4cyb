{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48cbc3ef",
   "metadata": {},
   "source": [
    "Project 2: Model Engineering\n",
    "===\n",
    "\n",
    "___\n",
    "\n",
    "Submitted by:\n",
    "\n",
    "* <u>*Arthur Humblot*</u>\n",
    "* <u>*Bekhzod Anvarov*</u>\n",
    "* <u>*Ghita El Belghiti*</u>\n",
    "\n",
    "\n",
    "University: **Politechnico di Torino**\n",
    "\n",
    "Academic Year: **2025 - 2026**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f9fa6",
   "metadata": {},
   "source": [
    "## 1. Task 1: Frequency-based baseline"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In Machine Learning problems, it is always good practice to compare against baseline solutions. Typically, one baseline involves a simple approach that helps determine whether simple choices and assumptions can already address the problem - before progressing to potentially more complex architectures like RNNs or GNNs.\n",
    "\n",
    "In this context, a suitable baseline is a **frequency-based** approach.\n",
    "\n",
    "Specifically:"
   ],
   "id": "d506221655f96d55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:16.976373Z",
     "start_time": "2025-12-05T11:28:16.974130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#imports here\n",
    "import pandas as pd"
   ],
   "id": "a5c2651a3218f7b3",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:17.271717Z",
     "start_time": "2025-12-05T11:28:17.022607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read dataset\n",
    "df_train = pd.read_json(\"../data/train.json\")\n",
    "df_test = pd.read_json(\"../data/test.json\")\n",
    "\n",
    "# instruction check\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ],
   "id": "957f594eb354418b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   api_call_sequence  is_malware\n",
      "0  [LdrGetDllHandle, LdrGetProcedureAddress, LdrL...           1\n",
      "1  [NtAllocateVirtualMemory, LdrLoadDll, LdrGetPr...           1\n",
      "2  [FindResourceExW, LoadResource, FindResourceEx...           1\n",
      "3  [FindResourceExW, LoadResource, FindResourceEx...           1\n",
      "4  [LdrGetProcedureAddress, SetErrorMode, LdrLoad...           1\n",
      "                                   api_call_sequence  is_malware\n",
      "0  [NtQueryValueKey, NtClose, NtOpenKey, NtQueryV...           1\n",
      "1  [LdrGetProcedureAddress, NtClose, NtOpenKey, N...           1\n",
      "2  [NtOpenKey, NtQueryValueKey, NtClose, NtOpenKe...           1\n",
      "3  [NtAllocateVirtualMemory, LdrLoadDll, LdrGetPr...           1\n",
      "4  [NtOpenKey, NtQueryValueKey, NtClose, LdrGetPr...           1\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Extract the vocabulary from your input dataset - that is, the **set of all the API calls** appearing in it",
   "id": "547b02adba1dfb4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:17.304464Z",
     "start_time": "2025-12-05T11:28:17.276639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# extract sequences(api) and labels\n",
    "train_seqs = df_train['api_call_sequence'].tolist()\n",
    "test_seqs = df_test['api_call_sequence'].tolist()\n",
    "\n",
    "train_labels = df_train['is_malware'].tolist()\n",
    "test_labels = df_test['is_malware'].tolist()\n",
    "\n",
    "# instruction check\n",
    "print(train_seqs[0][:5])\n",
    "print(f\"Type of sequence: {type(train_seqs[0]).__name__}\")"
   ],
   "id": "2a8afa56c4cff397",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LdrGetDllHandle', 'LdrGetProcedureAddress', 'LdrLoadDll', 'LdrGetProcedureAddress', 'LdrGetDllHandle']\n",
      "Type of sequence: list\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* **Q:** How many unique API calls does the training set contain?",
   "id": "46516f71c75af16a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:17.430978Z",
     "start_time": "2025-12-05T11:28:17.349863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create train vocabulary unique api\n",
    "train_vocab = set()\n",
    "\n",
    "for train_seq in train_seqs:\n",
    "    for api_call in train_seq:\n",
    "        train_vocab.add(api_call)\n",
    "\n",
    "print(f\"Number of unique API calls the training set contain: {len(train_vocab)}\")"
   ],
   "id": "e99b9d739ee25be3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique API calls the training set contain: 258\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And how many the test set?",
   "id": "90299d725737735"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:17.479543Z",
     "start_time": "2025-12-05T11:28:17.442187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create test vocal unique api\n",
    "test_vocab = set()\n",
    "\n",
    "for test_seq in test_seqs:\n",
    "    for api_call in test_seq:\n",
    "        test_vocab.add(api_call)\n",
    "\n",
    "print(f\"Number of unique API calls the test set contain: {len(test_vocab)}\")"
   ],
   "id": "c04e11cf73bf9f08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique API calls the test set contain: 232\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* **Q:** Are there any API calls that appear only in the test set (but not in the training set)? If yes, how many? And which one are they?",
   "id": "87294fd8c98f5826"
  },
  {
   "cell_type": "code",
   "id": "108f9e91",
   "metadata": {
    "lines_to_next_cell": 2,
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:17.507121Z",
     "start_time": "2025-12-05T11:28:17.504637Z"
    }
   },
   "source": [
    "# features, which appear only in test set, and not in train set\n",
    "only_in_test = test_vocab - train_vocab\n",
    "print(f\"Number of unique API calls only the test set contain(but not in the training set): {len(only_in_test)}\")\n",
    "print(f\"Unique API calls only the test set contain:\\n{only_in_test}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique API calls only the test set contain(but not in the training set): 3\n",
      "Unique API calls only the test set contain:\n",
      "{'ControlService', 'WSASocketA', 'NtDeleteKey'}\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:17.555091Z",
     "start_time": "2025-12-05T11:28:17.551753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sorted vocabulary\n",
    "train_vocab_sorted = sorted([i for i in train_vocab])\n",
    "test_vocab_sorted = sorted([i for i in test_vocab])\n",
    "\n",
    "# instruction check\n",
    "print(train_vocab_sorted[:5])\n",
    "print(test_vocab_sorted[:5])"
   ],
   "id": "882d16481fb09898",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CertOpenStore', 'CertOpenSystemStoreW', 'CoCreateInstance', 'CoCreateInstanceEx', 'CoGetClassObject']\n",
      "['CoCreateInstance', 'CoCreateInstanceEx', 'CoGetClassObject', 'CoInitializeEx', 'CoInitializeSecurity']\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* **Q:** Can you use the test vocabulary to build the new test dataframe? If not, how do you handle API calls in the test set that do not exist in the training vocabulary?",
   "id": "3a5b1a57dc850a7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:17.601305Z",
     "start_time": "2025-12-05T11:28:17.599536Z"
    }
   },
   "cell_type": "code",
   "source": "feature_names = train_vocab_sorted + ['<UNK>']",
   "id": "d8b562e4ddeaa11d",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We add **< UNK >** - for features unknown for train set and appears on test set only",
   "id": "ab5bb8973a305674"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Use this vocabulary as the **feature set**: for each row in the input dataset, count the **number of times** (frequency) each vocabulary term occurs",
   "id": "5c46374e99d9fdf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:17.955505Z",
     "start_time": "2025-12-05T11:28:17.645470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# map api with their positions\n",
    "api_to_idx = dict()\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    api_to_idx[feature_names[i]] = i\n",
    "\n",
    "# creating features for train\n",
    "X_train = list()\n",
    "\n",
    "for seq in train_seqs:\n",
    "    freq = [0 for _ in range(len(feature_names))]   # frequency vector for train features\n",
    "    for api_call in seq:\n",
    "        if api_call in api_to_idx:\n",
    "            freq[api_to_idx[api_call]] += 1\n",
    "    X_train.append(freq)\n",
    "\n",
    "# creating features for train\n",
    "X_test = list()\n",
    "\n",
    "for seq in test_seqs:\n",
    "    freq = [0 for _ in range(len(feature_names))]   # frequency vector for test features\n",
    "    for api_call in seq:\n",
    "        if api_call in api_to_idx:\n",
    "            freq[api_to_idx[api_call]] += 1     # UNK features, which are only on test\n",
    "        else:\n",
    "            freq[-1] += 1\n",
    "    X_test.append(freq)"
   ],
   "id": "f68bbf7b72d1deff",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* **Q:** One issue of this frequency-based approach is that it creates sparse vectors (i.e., vectors with many zeros per row):\n",
    "    * how many non-zero elements per row do you have on average in the training set?\n",
    "    * How many in the test set ?\n",
    "    * What is the ratio with respect to the number of elements per row?"
   ],
   "id": "4644eae288a8bf2c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T11:28:18.077993Z",
     "start_time": "2025-12-05T11:28:17.960729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sparsity for the train set (non-zero per row)\n",
    "nnz_train_per_row = list()  # num of non zeros\n",
    "\n",
    "for freq in X_train:\n",
    "    nnz_train_per_row.append(sum([1 if i > 0 else 0 for i in freq]))\n",
    "\n",
    "avg_non_zero_train = sum(nnz_train_per_row) / len(X_train)\n",
    "print(f\"Average non-zero elements per row in training set: {avg_non_zero_train}\")\n",
    "ratio_train = avg_non_zero_train / len(feature_names)\n",
    "print(f\"Ratio with respect to the number of elements per row in training set: {ratio_train}\")\n",
    "\n",
    "\n",
    "# sparsity for the test set (non-zero per row)\n",
    "nnz_test_per_row = list()  # num of non zeros\n",
    "\n",
    "for freq in X_test:\n",
    "    nnz_test_per_row.append(sum([1 if i > 0 else 0 for i in freq]))\n",
    "\n",
    "avg_non_zero_test = sum(nnz_test_per_row) / len(X_test)\n",
    "print(f\"Average non-zero elements per row in test set: {avg_non_zero_test}\")\n",
    "ratio_test = avg_non_zero_test / len(feature_names)\n",
    "print(f\"Ratio with respect to the number of elements per row in test set: {ratio_test}\")"
   ],
   "id": "8f3651049db881f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average non-zero elements per row in training set: 21.94707503828484\n",
      "Ratio with respect to the number of elements per row in training set: 0.08473774146055923\n",
      "Average non-zero elements per row in test set: 24.27870868562644\n",
      "Ratio with respect to the number of elements per row in test set: 0.09374018797539166\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\" This is temporary helper which is not part of lab activity !!! \"\"\"\n",
    "\n",
    "# ---------- Reused across Task 1–4 (keep these) ----------\n",
    "\n",
    "\"\"\"\n",
    "    df_train: pandas DataFrame for training data loaded from train.json\n",
    "    df_test: pandas DataFrame for test data loaded from test.json\n",
    "\n",
    "    train_seqs: list of lists, each inner list is a sequence of API call strings from the training set\n",
    "    test_seqs: list of lists, each inner list is a sequence of API call strings from the test set\n",
    "\n",
    "    y_train: list/array of labels (0 = goodware, 1 = malware) for training samples\n",
    "    y_test: list/array of labels (0 = goodware, 1 = malware) for test samples\n",
    "\n",
    "    train_vocab: set of unique API call strings observed in the training set\n",
    "    test_vocab: set of unique API call strings observed in the test set (used for analysis / OOV check)\n",
    "\n",
    "    train_vocab_sorted: sorted list of API call strings from train_vocab\n",
    "    feature_names: list of feature names for Task 1 (train_vocab_sorted + ['<UNK>'])\n",
    "                  later tasks may use a similar list for building ID/embedding vocabularies\n",
    "\n",
    "    api_to_idx: dictionary mapping API call string -> integer index\n",
    "          (for Task 1: column index in the frequency vector;\n",
    "          for Tasks 2–3 you will build a similar mapping for IDs/embeddings)\n",
    "\n",
    "    only_test: set of API call strings that appear only in test (test_vocab - train_vocab)\n",
    "        used to motivate the need for an <UNK> token / index\n",
    "\"\"\""
   ],
   "id": "d3897ee332bc8373"
  },
  {
   "cell_type": "markdown",
   "id": "187819eb",
   "metadata": {},
   "source": [
    "## 2. Task 2: Feed Forward Neural Network (FFNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c9aa1",
   "metadata": {},
   "source": [
    "## 3. Task 3: Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03658c14",
   "metadata": {},
   "source": [
    "## 4. Task 1: Graph Neural Network (GNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
